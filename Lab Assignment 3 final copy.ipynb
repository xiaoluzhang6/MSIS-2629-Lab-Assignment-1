{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-07T16:21:38.552372Z",
     "start_time": "2017-10-07T16:21:38.541491Z"
    }
   },
   "source": [
    "## Step 1: Data Wrangling\n",
    "Starting with the raw data, unwanted rows and columns are removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-07T06:48:20.100284Z",
     "start_time": "2017-10-07T06:48:19.455587Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas_datareader as pdr\n",
    "import requests as rq\n",
    "import fuzzywuzzy\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "\n",
    "# load data\n",
    "df = pd.read_csv('test_data.csv', delimiter=',')\n",
    "\n",
    "# replace header with first row of data\n",
    "\n",
    "new_header = df.iloc[0] #grab the first row for the header\n",
    "df = df[1:] #take the data less the header row\n",
    "df.columns = new_header #set the header row as the df header\n",
    "# drop unwanted columns\n",
    "df.drop(df.columns[[1,2,7,8,10,11,12,13,14,15,16,17]], axis=1,inplace=True)\n",
    "# drop unwanted row\n",
    "df.drop(df.index[0], inplace=True)\n",
    "\n",
    "# change type of YEAR column to numeric and to actual value\n",
    "df['YEAR'] = df['YEAR'].astype(int)\n",
    "df['YEAR'].replace([0,1,2,3,4,5,6,7,8,9,10,11,12,13,14],[2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2017],inplace=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially, my thought was that organizations belonging in the public sector will not have a ticker symbol; to minimize error messages when extracting financial data, I filter the dataset and get rid of entities belonging in those organizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-07T06:48:23.168981Z",
     "start_time": "2017-10-07T06:48:23.145845Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['web', 'financial', 'tech, retail', 'telecoms',\n",
       "       'government, military', 'government', 'retail', 'academic',\n",
       "       'energy', 'military', 'healthcare', 'tech',\n",
       "       'government, healthcare', 'web, gaming', 'gaming', 'media',\n",
       "       'military, healthcare', 'web, military', 'tech, web', 'transport',\n",
       "       'web, tech', 'legal', 'app'], dtype=object)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ORGANISATION'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-07T18:08:15.637128Z",
     "start_time": "2017-10-07T18:08:15.597683Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entity</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>records lost</th>\n",
       "      <th>ORGANISATION</th>\n",
       "      <th>METHOD OF LEAK</th>\n",
       "      <th>DATA SENSITIVITY</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AOL</td>\n",
       "      <td>2004</td>\n",
       "      <td>92000000</td>\n",
       "      <td>web</td>\n",
       "      <td>inside job</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Automatic Data Processing</td>\n",
       "      <td>2005</td>\n",
       "      <td>125000</td>\n",
       "      <td>financial</td>\n",
       "      <td>poor security</td>\n",
       "      <td>20</td>\n",
       "      <td>ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ameritrade Inc.</td>\n",
       "      <td>2005</td>\n",
       "      <td>200000</td>\n",
       "      <td>financial</td>\n",
       "      <td>lost / stolen device</td>\n",
       "      <td>20</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Citigroup</td>\n",
       "      <td>2005</td>\n",
       "      <td>3900000</td>\n",
       "      <td>financial</td>\n",
       "      <td>lost / stolen device</td>\n",
       "      <td>300</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Cardsystems Solutions Inc.</td>\n",
       "      <td>2005</td>\n",
       "      <td>40000000</td>\n",
       "      <td>financial</td>\n",
       "      <td>hacked</td>\n",
       "      <td>300</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0                       Entity  YEAR records lost ORGANISATION  \\\n",
       "2                          AOL  2004     92000000          web   \n",
       "3    Automatic Data Processing  2005       125000    financial   \n",
       "4              Ameritrade Inc.  2005       200000    financial   \n",
       "5                    Citigroup  2005      3900000    financial   \n",
       "6  Cardsystems Solutions Inc.   2005     40000000    financial   \n",
       "\n",
       "0        METHOD OF LEAK DATA SENSITIVITY ticker  \n",
       "2            inside job                1   None  \n",
       "3         poor security               20    ADP  \n",
       "4  lost / stolen device               20   None  \n",
       "5  lost / stolen device              300      C  \n",
       "6                hacked              300   None  "
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[~df['ORGANISATION'].isin([\"military\", \"government\",\"healthcare\",\"academic\",\"government, military\",\"government, healthcare\"])]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-07T06:48:32.821523Z",
     "start_time": "2017-10-07T06:48:32.813537Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df[['Entity','YEAR','records lost','ORGANISATION','METHOD OF LEAK','DATA SENSITIVITY']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-07T06:48:34.432555Z",
     "start_time": "2017-10-07T06:48:34.409064Z"
    }
   },
   "outputs": [],
   "source": [
    "# Querying for ticker. Only get those in NYSE or NASDAQ\n",
    "\n",
    "def get_symbol(entity):\n",
    "    url = \"http://d.yimg.com/autoc.finance.yahoo.com/autoc?query={}&region=1&lang=en\".format(entity)\n",
    "\n",
    "    result = rq.get(url).json()\n",
    "\n",
    "    for x in result['ResultSet']['Result']:\n",
    "        if fuzz.partial_ratio(entity, x['name']) >= 80:\n",
    "            if x['exchDisp'] == 'NYSE' or x['exchDisp'] == 'NASDAQ':\n",
    "                return x['symbol'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-07T06:48:36.727723Z",
     "start_time": "2017-10-07T06:48:36.707323Z"
    }
   },
   "outputs": [],
   "source": [
    "entities = df['Entity'].tolist() #put in list if match >=80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-07T06:49:25.367454Z",
     "start_time": "2017-10-07T06:48:38.343262Z"
    }
   },
   "outputs": [],
   "source": [
    "TickerList = []\n",
    "\n",
    "for y in entities:\n",
    "    symbol = get_symbol(y)\n",
    "    TickerList.append(symbol)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-07T17:43:22.432488Z",
     "start_time": "2017-10-07T17:42:21.837961Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ticker not found\n",
      "ticker not found\n",
      "ticker not found\n"
     ]
    }
   ],
   "source": [
    "# this is to catch companies not listed/no ticker\n",
    "\n",
    "stockData = pd.DataFrame(columns = ['Symbol','Date', 'Close'])\n",
    "for x in TickerList:\n",
    "    if x is not None:\n",
    "        try:\n",
    "            result = pdr.get_data_yahoo(x)\n",
    "            result = result.reset_index()  \n",
    "            result['Symbol'] = x\n",
    "            result = result[['Symbol', 'Date', 'Close']]\n",
    "            stockData = stockData.append(result)\n",
    "        except:\n",
    "            print('ticker not found')\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-07T06:51:50.523173Z",
     "start_time": "2017-10-07T06:51:48.780969Z"
    }
   },
   "outputs": [],
   "source": [
    "# write extracted data to file \n",
    "\n",
    "df.insert(loc = 6,column = 'ticker', value = TickerList)\n",
    "updated_data = pd.merge(df, stockData, left_on='ticker',right_on='Symbol', how='right')\n",
    "updated_data.to_csv('Lab3_data1.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Data Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-07T07:44:01.433313Z",
     "start_time": "2017-10-07T07:44:01.192662Z"
    }
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "df2 = pd.read_csv('Lab3_data1.csv', delimiter=',')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I split the data into two sets of data, records lost and stock price for organizations which incurred those loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-07T05:46:33.457688Z",
     "start_time": "2017-10-07T05:46:33.428677Z"
    }
   },
   "outputs": [],
   "source": [
    "stockPrice = df2[['Entity','Date','Close']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-07T05:07:09.987879Z",
     "start_time": "2017-10-07T05:07:09.977098Z"
    }
   },
   "outputs": [],
   "source": [
    "recordsLost = df2[['YEAR','Entity','records lost']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting records lost data first, I see that the most significant record loss were in companies Equifax, JP Morgan, and Heartland; so in general, financial institutions had the most significant record loss. I decided to dig further into these organizations.\n",
    "\n",
    "Table 0: https://public.tableau.com/views/Lab3_0_0RecordsLost/Sheet1?:embed=y&:display_count=yes&publish=yes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-07T07:04:17.702607Z",
     "start_time": "2017-10-07T07:04:17.626261Z"
    }
   },
   "outputs": [],
   "source": [
    "equifax = df2[df2.Entity ==\"Equifax\"]\n",
    "equifax.to_csv('Lab3Equifax.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After looking further into the above 3 institutions, Equifax had the most significant confirming data; there was a big drop in stockprice in the period of data breach (September, 2017). \n",
    "\n",
    "Table 0.1: https://public.tableau.com/views/Lab3_0_1EquifaxStockPriceHistoryClosingPrice/Sheet1?:embed=y&:display_count=yes&publish=yes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Step 3. Visualization Final Version : https://public.tableau.com/views/LabAssignment3_1/Sheet1?:embed=y&:display_count=yes&publish=yes\n",
    " \n",
    " In this final version, there's a strong correlation between data lost and stock price; confirming that financial market does punish data breach heavily. \n",
    " \n",
    " However, in hindsight, this result was biased as it only examined one industry; if I had plotted companies in the public sector (healthcare), I would'have found that the trend is much less severe. From looking at other's charts (plotting data from healthcare industry) in class, I could see that the correlation between stock price and record breach is not strong at all, thereby, refuting the initial claim.\n",
    "\n",
    "Going in further, I could have examined the stock price trend couple months before and after the breach,just to see if there is a trend in the behavior of the market; for example, how long does it take for the financial market recover from an incident such as data breach, and if the stock price was very optimistic before the incident (on a climbing trend), does the organizatio get punished more heavily in event of a data breach.\n",
    "\n",
    "For this lab session, I had focused too much on the technical part of the assignment and spend more time on small trivial problems such as formating; more focus should have been put on the overall big picture and the underlying message of the data. I also could have incorporated more features of Tableau for data cleanup and saved time in developing codes in python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resources Used:\n",
    "\n",
    "Retriving Ticker: https://stackoverflow.com/questions/38967533/retrieve-company-name-with-ticker-symbol-input-yahoo-or-google-api\n",
    "\n",
    "FuzzyWuzzy to find match: Classmate helped with coding and inserting into table\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
